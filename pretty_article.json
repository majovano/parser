[
  {
    "title": "Deepgram Self-Hosted December 2024 Release (241226)",
    "description": "quay.io/deepgram/self-hosted-api:release-241226 quay.io/deepgram/self-hosted-engine:release-241226 quay.io/deepgram/self-hosted-license-proxy:release-241226 quay.io/deepgram/self-hosted-billing:release-241226 .  No model update is required. Use the request parameter  profanity_filter=true . Increases robustness of handling TTS text inputs. Adds new   for monitoring latency in Grafana or similar applications. Reminder: The Deepgram image repositories have been updated to reflect our \"self-hosted\" naming. Images should now be pulled from the\u00a0 self-hosted-* \u00a0Quay repositories. For the next eight months, both\u00a0 onprem-* \u00a0and\u00a0 self-hosted-* \u00a0image repositories will receive identical image updates monthly, and we will announce image tags in the\u00a0 self-hosted \u00a0repositories. Subsequently, we will only publish new images to\u00a0 self-hosted-* \u00a0repos, deprecating\u00a0 onprem-* \u00a0repository variants. Keeps our software up-to-date."
  },
  {
    "title": "Improved Profanity Filtering",
    "description": "The profanity filtering system ( profanity_filter=true ) now includes: An expanded database of profane words and phrases Real-time filtering support for streaming audio Standardized asterisk replacement for filtered content Note: Profanity Filtering is available for English-only. Previously, our system would replace detected profanity with similar-sounding words. With this update, all identified profane content is now consistently replaced with asterisks, providing clearer and more predictable output. See our  to learn more. For Self-Hosted customers, please reach out to your Deepgram contact if you'd like to use the updated feature."
  },
  {
    "title": "Deepgram Self-Hosted November 2024 Release (241121)",
    "description": "quay.io/deepgram/self-hosted-api:release-241121 quay.io/deepgram/self-hosted-engine:release-241121 quay.io/deepgram/self-hosted-license-proxy:release-241121 quay.io/deepgram/self-hosted-billing:release-241121 Increases the maximum throughput for pre-recorded transcription of longer audio durations. Improves beta streaming entity formatting. Reminder: The Deepgram image repositories have been updated to reflect our \"self-hosted\" naming. Images should now be pulled from the\u00a0 self-hosted-* \u00a0Quay repositories. For the next nine months, both\u00a0 onprem-* \u00a0and\u00a0 self-hosted-* \u00a0image repositories will receive identical image updates monthly, and we will announce image tags in the\u00a0 self-hosted \u00a0repositories. Subsequently, we will only publish new images to\u00a0 self-hosted-* \u00a0repos, deprecating\u00a0 onprem-* \u00a0repository variants. Keeps our software up-to-date."
  },
  {
    "title": "Deepgram Self-Hosted October 2024 Release (241024)",
    "description": "quay.io/deepgram/self-hosted-api:release-241024 quay.io/deepgram/self-hosted-engine:release-241024 quay.io/deepgram/self-hosted-license-proxy:release-241024 quay.io/deepgram/self-hosted-billing:release-241024 Adds new  ! Improves beta streaming entity formatting. Reminder: The Deepgram image repositories have been updated to reflect our \"self-hosted\" naming. Images should now be pulled from the\u00a0 self-hosted-* \u00a0Quay repositories. For the next ten months, both\u00a0 onprem-* \u00a0and\u00a0 self-hosted-* \u00a0image repositories will receive identical image updates monthly, and we will announce image tags in the\u00a0 self-hosted \u00a0repositories. Subsequently, we will only publish new images to\u00a0 self-hosted-* \u00a0repos, deprecating\u00a0 onprem-* \u00a0repository variants. Keeps our software up-to-date."
  },
  {
    "title": "Deepgram Self-Hosted September 2024 Release (240927)",
    "description": "quay.io/deepgram/self-hosted-api:release-240927 quay.io/deepgram/self-hosted-engine:release-240927 quay.io/deepgram/self-hosted-license-proxy:release-240927 quay.io/deepgram/self-hosted-billing:release-240927 Improves efficiency of streaming diarization. Adds multichannel support for   message. Adds broader support in Engine container for model auto-loading during runtime.  Enables the keyword-boosting feature for streaming by default. Improves opt-in beta entity recognition and entity formatting. Reminder: The Deepgram image repositories have been updated to reflect our \"self-hosted\" naming. Images should now be pulled from the\u00a0 self-hosted-* \u00a0Quay repositories. For the next eleven months, both\u00a0 onprem-* \u00a0and\u00a0 self-hosted-* \u00a0image repositories will receive identical image updates monthly, and we will announce image tags in the\u00a0 self-hosted \u00a0repositories. Subsequently, we will only publish new images to\u00a0 self-hosted-* \u00a0repos, deprecating\u00a0 onprem-* \u00a0repository variants. Keeps our software up-to-date."
  },
  {
    "title": "Deepgram Websocket Text to speech API",
    "description": "Deepgram is excited to announce the launch of our WebSocket API for our text-to-speech product, Aura. We've listened to users' pain points when building conversational AI agents with LLMs and TTS (text-to-speech). With the WebSocket API, you can minimize latency by sending text tokens from any LLM as soon as they\u2019re generated, reducing delays and creating a smoother experience. It also makes handling user interruptions easier and provides a simple way to estimate the number of concurrent conversations you can support, with one WebSocket per conversation. To learn more, check out our getting started guide:\n"
  },
  {
    "title": "Nova-2 Cantonese",
    "description": "model=nova-2&language=zh-HK We're excited to announce that we have released  Cantonese support  in our next-gen speech-to-text model, Nova-2. See our   for information. For Self-Hosted customers, please reach out to your Deepgram contact if you'd like to use the new language."
  },
  {
    "title": "Deepgram Self-Hosted August 2024 Release (240827)",
    "description": "quay.io/deepgram/self-hosted-api:release-240827 quay.io/deepgram/self-hosted-engine:release-240827 quay.io/deepgram/self-hosted-license-proxy:release-240827 quay.io/deepgram/self-hosted-billing:release-240827 Deepgram's core products are available to host both on-premises and in the cloud. Official resources have been updated to refer to a  , instead of an \"onprem\" product offering, to align the product name with industry naming standards. Enables   of 50+   for English pre-recorded audio. Previously, this feature has only been available on our hosted endpoint. Expands our   capabilities to support 50+   for English pre-recorded audio. Keeps our software up-to-date."
  },
  {
    "title": "Nova-2 Air Traffic Control Speech to Text",
    "description": "model=nova-2-atc We're excited to announce that we have released a use case model for transcribing English  air traffic control  audio in our next-gen speech-to-text model, Nova-2. With full pre-recorded and streaming capabilities, it's optimized for noisy and jargon heavy air traffic control conversations. See our   for information. For Self-Hosted customers, please reach out to your Deepgram contact if you'd like to use the new model."
  },
  {
    "title": "Deepgram Model Metadata GA ",
    "description": "The Deepgram Models endpoint allows users to efficiently query all available public models or private models and determine which models they have access to. You can also use this endpoint to retrieve important model metadata for all Deepgram Models.  To learn more about this feature see our "
  },
  {
    "title": "Deepgram Aura Text to Speech - Ringing Issue Fixed",
    "description": "Deepgram Aura text-to-speech has resolved user-reported issues with faint ringing background noise. With the new model version, ringing background noise issues have been resolved for all voices.  Please check out our voice selection page to see the voices that we offer: "
  },
  {
    "title": "Deepgram Self-Hosted July 2024 Release (240725)",
    "description": "deepgram/onprem-api:release-240725 deepgram/onprem-engine:release-240725 deepgram/onprem-license-proxy:release-240725 deepgram/onprem-billing:release-240725 deepgram/onprem-dgtools:release-240725 Enables transcription of mixed English and Spanish audio, using our new English/Spanish   model. (Beta) Enables   of 50+   for English pre-recorded audio. Previously, this feature has only been available on our hosted endpoint. (Beta) Expands our   capabilities to support 50+   for English pre-recorded audio. (Beta) Enables next-generation streaming entity formatting for English audio. Formats entities for maximum readability and naturalness, such as dates, times, emails, and mailing addresses. Logs a warning if a user-provided TOML configuration file path is invalid and the default fallback configuration is used. Reduces Engine container logging noise by downgrading log-level of the  /models  endpoint heartbeat from  INFO  to  DEBUG . Fixes an error when summarizing empty audio. Returns empty audio instead of a 400 error when unutterable text is provided for TTS. Keeps our software up-to-date."
  },
  {
    "title": "Entity Detection is now GA",
    "description": "We're thrilled to announce the GA release of our entity detection feature for Deepgram Hosted customers.  detect_entities=true By including the new parameter in your pre-recorded speech-to-text requests (STT), you can identify and extract over 50 unique entity types. This release brings up to a 74% absolute improvement in detecting email addresses, names, locations, phone numbers, social security numbers, and more. See our  and   to learn more about using Entity Detection. For Self-Hosted customers, please reach out to your Deepgram contact if you'd like to use the new feature in beta."
  },
  {
    "title": "Nova-2 Spanglish",
    "description": "model=nova-2&language=multi We're excited to announce that we have released our  multilingual code-switching support (Spanish and English)  in our next-gen speech-to-text model, Nova-2. With full pre-recorded and streaming capabilities, and word-level language classification, it's optimized for all your complex code-switching use cases in an increasingly multilingual world. See our   for information. For Self-Hosted customers, please reach out to your Deepgram contact if you'd like to use the new feature."
  },
  {
    "title": "Deepgram Self-Hosted June 2024 Release (240627)",
    "description": "deepgram/onprem-api:release-240627 deepgram/onprem-engine:release-240627 deepgram/onprem-license-proxy:release-240627 deepgram/onprem-billing:release-240627 deepgram/onprem-dgtools:release-240627 Adds more verbose logging for audio content length. Keeps our software up-to-date."
  },
  {
    "title": "Deepgram Self-Hosted May Release (240528)",
    "description": "deepgram/onprem-api:release-240528 deepgram/onprem-engine:release-240528 deepgram/onprem-license-proxy:release-240528 deepgram/onprem-billing:release-240528 deepgram/onprem-dgtools:release-240528 Surfaces  dg-model-name ,  dg-model-uuid ,  dg-char-count ,  dg-request-id ,  dg-error  request response headers to CORS requests. Useful for TTS in the context of web development, given that the response body is audio. Improves entity formatting. Stability improvements, security patches, and bug fixes.\ud83d\udc1b"
  },
  {
    "title": "Improved Nova-2 Medical Model",
    "description": "model = nova-2-medical Deepgram has done additional training to our Nova-2 Medical Model to improve accuracy and expand the model vocabulary - resulting in a 16% relative improvement in word recall rate (WRR) on key medical terminology. See our docs for the full list of models available:  There should be no code changes required on your end - all requests with model=nova-2-medical will automatically get the latest version with the fix applied. For On-Premises customers, please reach out to your Deepgram contact if you'd like to update your models."
  },
  {
    "title": "Aura Text-to-speech available on Deepgram Playground ",
    "description": "Deepgram Aura is now available on Deepgram Playground: "
  },
  {
    "title": "Nova-2 Now Supports 36 Languages",
    "description": "We're excited to announce that  we now support 36 languages  in our next-gen speech-to-text model, Nova-2. This includes most languages supported by previous models, as well as many new languages - all now with even better performance! See our\u00a0 \u00a0for the up-to-date full list of supported languages, or explore our\u00a0 \u00a0for information on how to call each available language model. Nova-2 Now Supports: Bulgarian Catalan Chinese (Mandarin, Simplified) Chinese (Mandarin, Traditional) Czech Danish Dutch English Estonian Finnish Flemish French German German (Switzerland) Greek Hindi Hungarian Indonesian Italian Japanese Korean Latvian Lithuanian Malay Norwegian Polish Portuguese Romanian Russian Slovak Spanish Swedish Thai Turkish Ukrainian Vietnamese For On-Premises customers, please reach out to your Deepgram contact if you'd like to update your models."
  },
  {
    "title": "Deepgram Self-Hosted April 2024 Release (240426)",
    "description": "deepgram/onprem-api:release-240426 deepgram/onprem-engine:release-240426 deepgram/onprem-license-proxy:release-240426 deepgram/onprem-billing:release-240426 deepgram/onprem-dgtools:release-240426 Adds support for Aura text-to-speech (TTS) on a new  speak/  endpoint! \ud83d\udde3\ufe0f Improves entity formatting. Improves intelligence features (sentiment, intents, topics, summarization). Lengthens the default streaming timeout from 10 seconds to 12 seconds, to align with Deepgram's hosted API. Adds configuration value ( max_concurrently_loaded_models)  to set an upper limit on the number of models loaded into memory, to mitigate memory errors and performance issues. Stability improvements, security patches, and bug fixes. \ud83d\udc1b"
  },
  {
    "title": "Deepgram Aura Text-to-speech - Bug Fixes ",
    "description": "Deepgram Aura text-to-speech has resolved user-reported issues, including: Quotation Mark Handling - You can now include quotation marks (\" \") in the text-input, and it correctly pronounces words. Empty Audio Outputs - Previously, our TTS API in rare occasions produced empty audio outputs despite non-empty text-inputs. This issue has been resolved. \n\nTo learn more about how to get started with  , check out our   in docs. "
  },
  {
    "title": "Deepgram Aura Text-to-Speech Improved Volume Consistency",
    "description": "We've improved the consistency of volume output levels across all voices of our Aura text-to-speech model.  Now, users will see:  Consistent volume levels across all of our model voices Consistent volume levels across clips generated from a single model voice To learn more about Aura text-to-speech check out our   and  . "
  },
  {
    "title": "Deepgram Self-Hosted March 2024 Release (240325)",
    "description": "deepgram/onprem-api:release-240325 deepgram/onprem-engine:release-240325 deepgram/onprem-license-proxy:release-240325 deepgram/onprem-billing:release-240325 deepgram/onprem-dgtools:release-240325 \u2757To support our new token-based features when upgrading from the January 2024 release or earlier ( 240104 ), the License Proxy container (and Billing container, if using) must be updated either alongside or in advance of the Engine and API containers. Deepgram recommends a blue-green deployment of the License Proxy container if deploying concurrently. You will experience a service outage if you attempt to run the new Engine and API containers before the License Proxy container is updated. Please see   for deployment recommendations. Audio transcoding improvements. Stability improvements, security patches, and bug fixes.\ud83d\udc1b"
  },
  {
    "title": "Deepgram Self-Hosted February Release (240228)",
    "description": "Please find additional deployment information for this release  . deepgram/onprem-api:release-240228 deepgram/onprem-engine:release-240228 deepgram/onprem-license-proxy:release-240228 deepgram/onprem-billing:release-240228 deepgram/onprem-dgtools:release-240228 \u2757To support our new token-based features, the License Proxy container (and Billing container, if using) must be updated either alongside or in advance of the Engine and API containers. Deepgram recommends a blue-green deployment of the License Proxy container if deploying concurrently. You will experience a service outage if you attempt to run the new Engine and API containers before the License Proxy container is updated. Please see   for deployment recommendations. Major feature release: Support for all  , including summarization, sentiment analysis, intent recognition, and topic detection. These features are available for both   and  . The License Proxy was updated to begin normal operations without requiring an explicit check-in from the API or Engine.\u00a0This update allows for additional License Proxy containers to be deployed as backups to the primary container. In addition, the memory footprint of the license proxy was significantly reduced when operating in cached-trust mode.  now includes fields for the channel where the utterance ended, as well as the timestamp of the last word spoken. A new   event pairs well with UtteranceEnd to detect when a person has started speaking during a stream. Fixed a bug for streaming where keywords were occasionally resulting in missing words in final transcripts. Stability improvements, security patches, and bug fixes.\ud83d\udc1b"
  },
  {
    "title": "Updated Nova-2 Model (English, Pre-recorded) - Improved Word Recognition",
    "description": "model = nova-2 Deepgram has done additional training to our Nova-2 General Model for English to improve accuracy for pre-recorded transcription, specifically addressing an issue with missing words / phrases.  We intend to roll out similar updates for streaming transcription and across other Nova-2 tier models over the next two weeks. There should be no code changes required on your end - all requests with model=nova-2 will automatically get the latest version with the fix applied. For On-Premises customers, please reach out to your Deepgram contact if you'd like to update your models."
  },
  {
    "title": "Deepgram Self-Hosted January Release (240104)",
    "description": "deepgram/onprem-api:release-240104 deepgram/onprem-engine:release-240104 deepgram/onprem-license-proxy:release-240104 deepgram/onprem-billing:release-240104 deepgram/onprem-dgtools:release-240104 Improved accuracy for timestamps and punctuation for recognized  . Stability improvements, security patches, and bug fixes.\ud83d\udc1b"
  },
  {
    "title": "Deepgram Releases Improved SDKs",
    "description": "The Developer Experience Team at Deepgram has been working the last several months on greatly improving our SDKs (Software Development Kits)  so developers have an easier time integrating with the Deepgram API.  We are happy to announce you can now upgrade to the next major version of our improved SDKs for JavaScript, Go , Python and .NET to benefit from many \"quality of life\" improvements and added functionality.  Please refer to the SDK repository and blog post for more details on each major release.  (Now officially supported by Deepgram!) If you upgrade your SDK version let us know how it goes in our Developer Communities on or on  ! Happy Coding \ud83d\ude80"
  },
  {
    "title": "Deepgram Self-Hosted December Release (231207)",
    "description": "deepgram/onprem-api:release-231207 deepgram/onprem-engine:release-231207 deepgram/onprem-license-proxy:release-231207 deepgram/onprem-billing:release-231207 deepgram/onprem-dgtools:release-231207 Improved support for container health checks/probes. There are now native endpoints available for all Deepgram containers to help you more easily manage container lifecycles and system maintenance. These probes can be configured with Kubernetes, or any other container orchestration technology that supports health probes.  Stability improvements, security patches, and bug fixes.\ud83d\udc1b"
  },
  {
    "title": "Deepgram Self-Hosted November Release (231114)",
    "description": "deepgram/onprem-api:release-231114 deepgram/onprem-engine:release-231114 deepgram/onprem-license-proxy:release-231114 deepgram/onprem-billing:release-231114 deepgram/onprem-dgtools:release-231114 Support for Nova 2 models in  . License Proxy and Billing containers now accept configuration files  license-proxy.toml  and  billing.toml , similar to API\u2019s  api.toml  and Engine\u2019s  engine.toml . Stability improvements, security patches, and bug fixes.\ud83d\udc1b"
  },
  {
    "title": "Improvements to Language Detection",
    "description": "Deepgram now offers the ability to restrict which languages will be detected by Deepgram's language detection algorithm. If you currently use the  detect_language=true  feature of Deepgram but your audio files are, for example, only in English and Spanish, you can improve the accuracy of your results by restricting which languages will be detected. Here's an example of how to restrict the detectable languages to only English ( en ) and Spanish ( es ): This functionality is available for pre-recorded audio and Deepgram's models (not Whisper). For more information, head over to our  ."
  },
  {
    "title": "Announcing Nova-2 GA & Additional Language Support",
    "description": "We are pleased to announce additional language support and the General Availability (GA) of Nova-2, our newest speech-to-text model. Nova-2 presents the new state-of-the-art in speech recognition. Read about Nova-2's performance and benchmarks in\u00a0 . The complete list of available use cases and languages can be found in our  .  Nova-2 is available to all Pay as you Go and Growth customers. Premium customers will have access to Nova-2 at contracted Nova rates. If you are a Premium customer and do not have access, please reach out to your account team. Pricing for Nova-2 is available at\u00a0 ."
  },
  {
    "title": "Deepgram Self-Hosted October Release (231026)",
    "description": "deepgram/onprem-api:release-231026 deepgram/onprem-engine:release-231026 deepgram/onprem-license-proxy:release-231026 deepgram/onprem-billing:release-231026 deepgram/onprem-dgtools:release-231026 More control with language detection features! You can now  , and view the   in returned ASR results. Adjusted order of operations with   to more consistently return a request ID immediately. Improved model loading logic. If you have explicit model loading directives under the features section of your  engine.toml  configuration file, you can remove it when upgrading to more recent releases. The minimum supported CUDA runtime version for onprem-engine has changed from 11.3.1 to 12.1.1. Systems using NVIDIA drivers before version 525.60.13 might encounter errors when attempting to start this release of onprem-engine. Deepgram recommends installing the latest NVIDIA drivers for maximum compatibility, stability, and performance. Stability improvements, security patches, and bug fixes.\ud83d\udc1b \n"
  },
  {
    "title": "Deepgram Log Usage Data limited to 90 days",
    "description": "On  Oct 18th 2023  Deepgram will be introducing a 90 day limit on the storage of log usage data for all of our customers.\u00a0 What this means: In the  > Usage > Logs users will now only be able to query for log data for up to 90 days of time. When using the Deepgram API   endpoint users will now only be able to query for usage data up to 90 days of time. You can still retrieve   for greater than 90 days.  Questions? Please refer to our Documentation for more details on "
  },
  {
    "title": "Improved Redaction Functionality",
    "description": "Deepgram\u2019s latest update offers enhanced redaction options for customers submitting pre-recorded audio to our hosted endpoint. Customers can now select specific types of entities, like locations, URLs, or names, to be redacted from their transcriptions. Here\u2019s an example of how to accomplish redacting different types of entities (in this case, city names, ages, and emails): For more information, head over to our  ."
  },
  {
    "title": "Deepgram Self-Hosted September Release (230920)",
    "description": "deepgram/onprem-api:release-230920 deepgram/onprem-engine:release-230920 deepgram/onprem-license-proxy:release-230920 deepgram/onprem-billing:release-230920 deepgram/onprem-metrics-server:release-230920 deepgram/onprem-dgtools:release-230920 Support for  . Significant improvements in diarization quality for batch requests.  Addresses a memory leak in  onprem-engine  that originated in a upstream dependency. This memory leak was only present in the August (230804) release. onprem-dgtools  now accepts licensing information passed via the  DEEPGRAM_API_KEY  environment variable, similar to  onprem-api  and  onprem-engine . Other stability improvements & bug fixes.\ud83d\udc1b"
  },
  {
    "title": "Introducing Nova-2 Early Access",
    "description": "Deepgram is excited to announce early access to our next-gen speech-to-text model, Nova-2. As shared in our  , Nova-2:  Outperforms all alternatives in terms of accuracy, speed, and cost ( ). Is 18% more accurate than our previous Nova model and offers a 36% relative WER improvement over OpenAI Whisper (large). Pay as You Go and Growth users may access this model immediately in the   or by requesting  model=nova-2-ea  in their API requests. Enterprise customers can reach out to their account representative or   for access.  Nova-2 Early Access supports hosted and on-prem transcription of pre-recorded and streaming English audio. Read more about Nova-2 in the\u00a0 ."
  },
  {
    "title": "Deepgram Self-Hosted August Release (230804)",
    "description": "deepgram/onprem-api:1.97.1 deepgram/onprem-engine:3.53.6 deepgram/onprem-license-proxy:1.4.2 deepgram/onprem-billing:1.7.2 deepgram/onprem-metrics-server:2.0.6 deepgram/onprem-dgtools:2.1.4 deepgram/onprem-api:release-230804 deepgram/onprem-engine:release-230804 deepgram/onprem-license-proxy:release-230804 deepgram/onprem-billing:release-230804 deepgram/onprem-metrics-server:release-230804 deepgram/onprem-dgtools:release-230804 Summarization efficiency improvements for broader GPU compatibility. Summarization-related errors and warnings produced by API calls have been expanded and made more detailed; please see  . Opus compatibility improvements with multichannel audio. Added a configuration parameter for batch sizes specifically for Whisper models. Please contact your account manager for more details. Added additional error reporting for streaming-related failures when the initial request includes the  debug=true  query parameter. Stability improvements and bug fixes.\ud83d\udc1b"
  },
  {
    "title": "Introducing New Summarization",
    "description": "We're excited to announce the release of our first domain-specific language model (DSLM) for speech summarization of call center interactions. You can request our new Summarization API  endpoint by adding a summarize parameter set to v2 in the API call. It will then return a summary object in the response body of the output. The summary object includes status and a concise summary of the entire conversation. The URL query to call the DSLM-powered Summarization API might look like this: https://api.deepgram.com/v1/listen?summarize=v2 Example curl request: You can send requests to the API with an Authorization header that references your project's API key Authorization: Token YOUR_DEEPGRAM_API_KEY The output response will contain the generated summary based on the provided audio. Summarization V2  supports English and Pre-Recorded audio. Primary difference between V1 (summarize=true) and V2 (summarize=v2) V1 provides summaries per channel. V2 provides a single summary across all the channels. V1 response contains summary objects (with summary, start, and end word). V2 response contains a single object with result and short key. Learn more about using our new  Test Summarization V2 using our  We are thrilled to get this feature into your hands and await your feedback. Please share it with us at\u00a0 \u00a0or your dedicated support channel."
  },
  {
    "title": "Deepgram Self-Hosted July Release (230705)",
    "description": "deepgram/onprem-api:1.95.0 deepgram/onprem-engine:3.53.0 deepgram/onprem-license-proxy:1.4.1 deepgram/onprem-billing:1.7.1 deepgram/onprem-metrics-server:2.0.6 deepgram/onprem-dgtools:2.1.4 deepgram/onprem-api:release-230705 deepgram/onprem-engine:release-230705 deepgram/onprem-license-proxy:release-230705 deepgram/onprem-billing:release-230705 deepgram/onprem-metrics-server:release-230705 deepgram/onprem-dgtools:release-230705 Support for license keys created and managed from  . Support for new Domain-Specific Language Model powered summarization.  . The minimum supported CUDA runtime version for onprem-engine has changed from 11.0.3 to 11.3.1. Systems using NVIDIA drivers before version 450.80.02 might encounter errors when attempting to start this release of onprem-engine. Deepgram recommends installing the latest NVIDIA drivers for maximum compatibility, stability, and performance. Reduction in frequency of hallucinations when using Deepgram enhanced models. Improvements to accuracy of reported word times when using existing Whisper models. Duration values specified in the onprem-api configuration file can now include unit suffixes. For example, instead of writing 480 it is now possible to write 4m. Values with no suffix are assumed to be seconds. Stability improvements and bug fixes.\ud83d\udc1b"
  },
  {
    "title": "Introducing Nova support for the Spanish language",
    "description": "Nova is Deepgram's most powerful and affordable speech-to-text model. Training on this model spans over 100 domains and 47 billion tokens, making it the deepest-trained automatic speech recognition (ASR) model to date. Nova doesn't just excel in one specific domain \u2014 it is ideal for a wide array of voice applications that require high accuracy in diverse contexts. This model now support the Spanish language es and es-419.  Learn more about using our new  Quickly test out this new Model using our  Learn more about "
  },
  {
    "title": "Deepgram Self-Hosted June Release (230606)",
    "description": "deepgram/onprem-api:1.92.2 deepgram/onprem-engine:3.48.2 deepgram/onprem-license-proxy:1.4.1 deepgram/onprem-billing:1.7.1 deepgram/onprem-metrics-server:2.0.6 deepgram/onprem-dgtools:2.1.4 This release marks the first official Deepgram On-premises release to include support for a release tag. Instead of specifying a specific version tag for the individual container images, all of the images now support the  release-230606  image tag. deepgram/onprem-api:release-230606 deepgram/onprem-engine:release-230606 deepgram/onprem-license-proxy:release-230606 deepgram/onprem-billing:release-230606 deepgram/onprem-metrics-server:release-230606 deepgram/onprem-dgtools:release-230606 New, easy-to-use deployments with embedded default configurations in the container images. Simply add the container environment variable  DEEPGRAM_API_KEY  to the  docker-compose.yml  stanzas for the  api  and  engine  container images. For more information, refer to the on-prem deployment documentation for your specific deployment OS. Deepgram\u2019s new Speaker Diarization architecture with 53.1% improved accuracy overall from the previous version, a 10X faster turnaround time, and language-agnostic support, unlocking accurate speaker labeling for transcription use-cases around the globe. Deepgram\u2019s   detection feature which enables users to automatically detect the dominant language in an audio file and transcribe the output in the detected language, providing unparalleled accuracy in detecting and transcribing audio data in over 15+ languages and dialects, including English, Spanish, Hindi, Dutch, French, and German. Addresses an issue where  onprem-license-proxy  was inappropriately coloring logs when directed to output to a file. Addresses   in  onprem-license-proxy . Other stability improvements & bug fixes.\ud83d\udc1b"
  },
  {
    "title": "Stream KeepAlive",
    "description": "Customers can now keep Deepgram streaming connections open during periods where no audio data is being sent. Previously, if no audio was being sent over the websocket, connections would close after a short window of time. We\u2019ve introduced a new KeepAlive WebSocket message that clients can use to indicate to Deepgram that the WebSocket should be kept open even though no data is being sent through. For more information, visit our\u00a0 ."
  },
  {
    "title": "Improved Language Detection Capabilities",
    "description": "We are thrilled to release the enhanced version of our Automatic Language Detection feature (detect_language=true), now supporting over 15+ languages. Deepgram\u2019s Enhanced Language Detection is adept at identifying the primary language in an audio file and providing transcriptions in the detected language. To utilize the Language Detection API, simply use the following URL query format:\u00a0 https://api.deepgram.com/v1/listen?detect_language=true&punctuate=true The API Response will output the detected language. For example \u2013\u00a0 \u201cdetected_language\u201d: \u201ces\u201d To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s . \u00a0 If you have any questions, please reach out to us through your dedicated support channel."
  },
  {
    "title": "Improved Speaker Diarization",
    "description": "We\u2019ve recently released an improved version of Diarization (for PRE-RECORDED). Its advanced speaker separation accurately identifies speakers in complex audio streams, reducing errors where two speakers are identified as one. Additionally, the new diarizer can identify and count speakers more accurately, reducing instances where one speaker is split between two labels. The result is more readable transcripts. Please note that with the release of improved diarization, we will be deprecating the\u00a0 diarize_version \u00a0parameter and will be retiring the old diarizer. Currently, you can call the old diarizer using the below URL:\u00a0 https://api.deepgram.com/v1/listen?tier=enhanced&diarize=true&diarize_version=2021-07-14.0 To access the latest diarizer, all you need to do is add\u00a0 diarize=true \u00a0to your URL:\u00a0 https://api.deepgram.com/v1/listen?diarize=true We encourage you to switch to the improved Diarizer as soon as possible to ensure that you are taking advantage of the latest advancements in our technology. To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s . If you have any questions, please reach out to us through your dedicated support channel."
  },
  {
    "title": "Deepgram Self-Hosted April Release (230413)",
    "description": "deepgram/onprem-api:1.88.0 deepgram/onprem-engine:3.45.3 deepgram/onprem-license-proxy:1.4.0 deepgram/onprem-metrics-server:2.0.4 deepgram/onprem-billing:1.7.0 deepgram/onprem-dgtools:2.1.4 Support for\u00a0 \u00a0&\u00a0 . Support for a faster version of the Diarizer. Support for a new Prometheus\u00a0 /metrics \u00a0endpoint in\u00a0 onprem-engine . Please contact Deepgram Customer Success or refer to the\u00a0 \u00a0and\u00a0 \u00a0guides for more information. Resolves an issue where\u00a0 <unk> \u00a0was incorrectly appearing in transcription results."
  },
  {
    "title": "Introducing Deepgram Nova & Deepgram Whisper Cloud and On-Prem",
    "description": "We are pleased to announce the latest model releases to our speech recognition services. Deepgram Nova presents the new state-of-the-art in speech recognition. Read more about it in\u00a0 . Nova is available with our\u00a0 general \u00a0and\u00a0 phonecall \u00a0models. To access either, please use the following syntax in your request: General:\u00a0 model=nova \u00a0or\u00a0 model=general&tier=nova Phonecall:\u00a0 model=phonecall&tier=nova Support for Deepgram Nova includes: English language support. Pre-recorded and live streaming audio transcription. Use through Deepgram\u2019s Hosted API or\u00a0 \u00a0Deployments. Please view pricing at\u00a0 . Deepgram Whisper Cloud and Whisper On-Prem integrate\u00a0 \u00a0with Deepgram\u2019s powerful API and feature set. Deepgram Whisper Cloud and Whisper On-Prem can be accessed with the following API parameters: model=whisper \u00a0or\u00a0 model=whisper-SIZE Available sizes include: Note: You should not specify a\u00a0 tier \u00a0 when using Whisper models. Use of Deepgram Whisper Cloud is subject to a rate limit of 50 requests per minute or 15 concurrent requests. Support for Deepgram Whisper Cloud and Whisper On-Prem include: A selection of Deepgram\u2019s transcription features, including: OpenAI\u2019s\u00a0 . Pre-recorded transcription. Use through Deepgram\u2019s Hosted API or\u00a0 \u00a0 . Please view pricing at\u00a0 . To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s\u00a0 ."
  },
  {
    "title": "Endpointing",
    "description": "Deepgram is excited to announce a new version of the Endpointing feature. Endpointing is designed to get customers the fastest and most accurate transcripts. It can also help determine when someone has finished talking. Users can specify the amount of silence they want to wait for when someone finishes talking before Deepgram finalizes the transcript and returns it with the flag\u00a0 speech_final . The Endpointing feature utilizes a powerful Voice Activity Detection algorithm to determine when someone has stopped speaking. Once speech has finished, Deepgram is able to quickly finalize a transcription of the speech and return it, along with a\u00a0 speech_final \u00a0flag marking that an Endpoint was detected. This algorithm can be configured through our Endpointing feature. To find out more, head to our\u00a0 ."
  },
  {
    "title": "Deepgram Self-Hosted Release 230228",
    "description": "Deepgram released a new version of its on-premises solution. deepgram/onprem-api:1.83.0 deepgram/onprem-engine:3.43.4 deepgram/onprem-license-proxy:1.3.0 deepgram/onprem-metrics-server:2.0.3 deepgram/onprem-billing:1.5.3 deepgram/onprem-dgtools:2.1.3 Improvements to Smart Formatting. Improved usage reporting for multichannel, streaming, and NLU features. TLS support for streaming callbacks. Resolves an issue when parsing\u00a0 \u00a0or\u00a0 \u00a0encoded audio data. Resolves an issue which impacted Language Detection. Migrated to the\u00a0 \u00a0base images to resolve CVEs for the following components: Due to the base image change, it is recommended that users\u00a0 \u00a0their container images with the following command:\n docker image prune -a Other minor stability, error handling, and performance improvements."
  },
  {
    "title": "Updates to General Model (en-US) Base and Enhanced Tiers",
    "description": "New versions of our English (en-US) General model\u2019s Base and Enhanced tiers have greatly improved accuracy and throughput. We are incredibly excited to release these enhancements to our customers.\u00a0We are making the new tiers available for testing over the next two weeks so you can compare them to your current results. If you are interested in testing the new tiers please reach out to Deepgram support to enable access. We will be deploying the new tiers as defaults on March 14th, 2023. If you do not wish to use the new versions that will be deployed as the default on March 14, 2023, you may pin to previous versions by specifying the desired version as version={desired_version}. If no version is specified, we will use our latest version by default.\u00a0 Most recent previous versions of these tiers: Base (model=general) 2022-01-18.1 Enhanced (model=general) 2022-05-18.0 Deepgram support is always available to walk customers through updates, as well as resolve any issues that arise when upgrading."
  },
  {
    "title": "Improvements to Deepgram Redaction",
    "description": "We\u2019re excited to announce an update to our\u00a0 . Deepgram\u2019s hosted API for pre-recorded audio now uses a powerful entity detection model for redaction functionality. This model has the ability to find and tag sensitive information with a high degree of precision\u2014including PCI, social security numbers, or any string of numbers. When using our hosted API for pre-recorded audio, the output of our redaction feature has changed to be more descriptive. Previously, transcripts would be returned with a\u00a0 * \u00a0where an entity was redacted. Now, the type of entity detected and number of times it\u2019s appeared in the transcript will be returned instead. For example, if you chose to redact social security numbers, the output for \u201cMy social security number is five five five two two one one one one and his is six six six two two one three three three\u201d would appear in your transcript as \u201cMy social security number is [SSN_1] and his is [SSN_2]\u201d. If live streaming audio, or using our on-premise product, redaction output will continue to use\u00a0 * \u00a0in place of redacted information for the time being. Entity detection-based redaction is available for customers using our hosted API to send pre-recorded audio. We\u2019re hard at work building out this functionality for live-streamed audio and on-premise customers\u2014look out for another announcement when that\u2019s ready. Please see our\u00a0 \u00a0for more information about the Redaction feature."
  },
  {
    "title": "Deepgram Self-Hosted Release 230120",
    "description": "Deepgram released a new version of its on-premises solution. deepgram/onprem-api:1.78.0 deepgram/onprem-engine:3.39.2 deepgram/onprem-license-proxy:1.2.5 deepgram/onprem-billing:1.5.2 deepgram/onprem-metrics-server:2.0.2 Improvements to capitalization and punctuation output with the request parameter\u00a0 punctuate=true . Improved NLU usage reporting. The\u00a0 /status \u00a0endpoint now returns an\u00a0 HTTP 204 \u00a0code instead of\u00a0 HTTP 200 . Several improvements to streaming: Resolves an issue with support for audio data that uses the the\u00a0 . Resolves several CVEs for the following images: Other minor stability and performance improvements."
  },
  {
    "title": "Smart Format",
    "description": "We\u2019re excited to announce a new beta feature: Smart Format! Smart Format makes transcripts easy to read. It adds punctuation; formats things like dates, addresses, and tracking numbers; splits up transcripts for pre-recorded audio into paragraphs; and more. To get started, just specify smart_format=true in your batch or live-stream API request.\u00a0We\u2019ll be improving the results and adding even more formatting goodness to this feature over the coming months, so stay tuned. For more information, check out our\u00a0 ."
  },
  {
    "title": "Streaming Test Suite Release",
    "description": "We\u2019ve released a new open-source project designed to make it easier to get started with our live streaming transcription API: the\u00a0 The streaming test suite is designed to ensure you can stream basic audio to Deepgram before you begin building custom integrations. It also provides some sample Python code that may be helpful when creating your own integration. After you successfully run the streaming test suite, you\u2019ll be ready to integrate Deepgram with more complex audio sources. Happy building!"
  },
  {
    "title": "Deepgram Self-Hosted Release 221130",
    "description": "Deepgram released a new version of its on-premises solution. deepgram/onprem-api:1.75.1 deepgram/onprem-engine:3.39.2 deepgram/onprem-license-proxy:1.2.2 deepgram/onprem-billing:1.5.0 deepgram/onprem-metrics-server:2.0.1 For streaming requests,\u00a0 interim_results \u00a0now defaults to false. This parameter does not impact batch. For normal streaming requests, Deepgram recommends leaving this set to the default value. To change the default to true, modify your\u00a0 api.toml \u00a0with:\n [features] \n \u00a0 interim_results_on_by_default = true\u00a0 # default is false For streaming requests,\u00a0 endpointing \u00a0now defaults to true. This parameter does not impact batch. For normal streaming requests, Deepgram recommends leaving this set to the default value. To change the default to false, modify your\u00a0 api.toml \u00a0with:\n [features] \n \u00a0 endpointing_on_by_default = false\u00a0 # default is true Improved handling of\u00a0 punctuation \u00a0when\u00a0 redaction \u00a0is also enabled. Added support for audio data that uses the the\u00a0 . Error message formatting is now consistent with Deepgram Cloud: Added a new\u00a0 DG-Error \u00a0HTTP response header to provide information on failing\u00a0 HTTP 101 \u00a0WebSocket upgrades. Resolves the following CVEs in supporting libraries for\u00a0 deepgram/onprem-billing : Resolves the following CVEs in supporting libraries for\u00a0 deepgram/onprem-metrics-server : Other minor stability improvements. We welcome your feedback. Please share it with us at\u00a0 ."
  },
  {
    "title": "New Enhanced Hindi Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include Hindi to bring you the highest accuracy for Hindi support. For example, to call the Hindi model, the URL query might look like: https://api.deepgram.com/v1/listen?model=general&tier=enhanced&language=hi&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs."
  },
  {
    "title": "New Enhanced Swedish Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include Swedish to bring you the highest accuracy for Swedish support. For example, to call the Swedish model, the URL query might look like https://api.deepgram.com/v1/listen?model=general&tier=enhanced&language=sv&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs."
  },
  {
    "title": "New Enhanced Danish Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include Danish to bring you the highest accuracy for Danish support. For example, to call the Danish model, the URL query might look like https://api.deepgram.com/v1/listen?model=general&tier=enhanced&language=da&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs."
  },
  {
    "title": "New Base Danish Model",
    "description": "Deepgram is excited to announce a new Base Danish model. To call the Base Danish model, the URL query might look like https://api.deepgram.com/v1/listen?model=general&tier=base&language=da&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs."
  },
  {
    "title": "New Enhanced Tamil Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include Tamil to bring you the highest accuracy for Tamil support. For example, to call the Enhanced Tamil model, the URL query might look like https://api.deepgram.com/v1/listen?model=general&tier=enhanced&language=ta&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs."
  },
  {
    "title": "New Enhanced French Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include French to bring you the highest accuracy for French language support. For example, to call the Enhanced French Model, the URL query might look like https://api.deepgram.com/v1/listen?model=general&tier=enhanced&language=fr&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new Model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs."
  },
  {
    "title": "New Enhanced Norwegian Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include Norwegian to bring you the highest accuracy for Norwegian language support. For example, to call the Enhanced Norwegian Model, the URL query might look like https://api.deepgram.com/v1/listen?model=general&tier=enhanced&language=no&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new Model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs."
  },
  {
    "title": "New Enhanced Spanish (Latin America) Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include Spanish (Latin America) to bring you the highest accuracy for Spanish (Latin America) dialect support. For example, to call the Enhanced Spanish (Latin America) model, the URL query might look like https://api.deepgram.com/v1/listen?model=general&tier=enhanced&language=es-419&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs."
  },
  {
    "title": "Real-Time Debugging Improvements",
    "description": "Deepgram\u2019s\u00a0 \u00a0has been updated for enhanced usability. Deepgram will now return the request ID and any applicable error messages in the headers for the pre-WebSocket HTTP connection created for all streaming requests. The request ID is stored in the HTTP header named dg-request-id. This header is present in all requests, regardless of success or failure. In case of request failure, an additional HTTP header named dg-error will be included with the body of the error. Here\u2019s an example of accessing this information using the Python websocket library: Please note: if using Javascript in the browser, HTTP header information is not accessible due to inherent limitations in the Javascript WebSocket API. However, the headers are accessible if using NodeJS. I\u2019m Shir, the product manager for Deepgram\u2019s streaming. If you have any feedback about this change, or anything else around Deepgram, we\u2019d love to hear from you. Please let us know in our\u00a0 ."
  },
  {
    "title": "Update \u2013 New Diarizer (Support for all Audio files)",
    "description": "We\u2019ve made a change in our Diarizer to support all audio files, including very long audio files. With the recent change, requests for very long audio files for the new diarizer (files longer than 3 hours) will no longer return 400 error code and will provide the result as expected. You can access the new diarizer using the below URL: https://api.deepgram.com/v1/listen?diarize=true To learn more about the improved Diarizer, please see the\u00a0 \u00a0page in our documentation. Our customer\u00a0 \u00a0team is always available to work with you on any issues you may see with our latest version of the diarizer."
  },
  {
    "title": "Deepgram Self-Hosted Release 221031",
    "description": "Deepgram released a new version of its on-premises solution. deepgram/onprem-api:1.72.2 deepgram/onprem-engine:3.37.8 deepgram/onprem-license-proxy:1.2.2 deepgram/onprem-billing:1.4.0 deepgram/onprem-metrics-server:2.0.0 Deepgram On-premises users can now choose between Deepgram\u2019s\u00a0 Base \u00a0and\u00a0 Enhanced \u00a0models in an ASR request via the\u00a0 tier \u00a0query parameter, where\u00a0 tier=base \u00a0will select the\u00a0 Base\u00a0 model and\u00a0 tier=enhanced \u00a0will select the\u00a0 Enhanced \u00a0model. Deepgram On-premises deployments now support the following Understanding features (with the accompanying Understanding model deployed on-prem and the requisite configuration changes): Deepgram On-premises now supports the all-new \u201cCloseStream\u201d web socket message for closing your live audio streams. Please see the\u00a0 \u00a0changelog post for more information, or refer to the API documentation for\u00a0 . We welcome your feedback, please share it with us at\u00a0 ."
  },
  {
    "title": "Configure Numeral Formatting in Real Time",
    "description": "\nDeepgram\u2019s real-time API has been updated for enhanced usability. In addition to enabling\u00a0 \u00a0at the start of a stream via query parameter, numeral formatting can now be turned on and off at any point in an audio stream by sending a JSON\u00a0 Configure \u00a0message. Here\u2019s an example of sending a configuration message in Javascript: And an example in Python: To enable numeral formatting, specify\u00a0 numerals: true ; to disable it, specify\u00a0 numerals: false . As many configuration messages can be sent as desired during the stream. Currently, numerals is the only feature that can be turned on and off mid-stream, but we\u2019re excited to continue adding greater flexibility to our real-time API. Stay tuned! Hi, I\u2019m Shir! I\u2019m the product manager for Deepgram\u2019s real-time transcription API. If you have any feedback about this change, or anything else in our product, I\u2019d love to hear about it. Drop me an email:\u00a0 .\u00a0"
  },
  {
    "title": "Updates to the New Diarizer",
    "description": "We\u2019ve made a change in our recently released Diarizer that may affect you. Requests for very long audio files for the new diarizer (files longer than 3 hours) will temporarily return an error message with a 400 error code. The team is actively working to enable diarization for files longer than three hours. If your audio file is longer than 3 hours, you can use the old diarizer by adding an additional query parameter to your requests \u2013\u00a0 diarizer_version=2021-7-14.0 If your audio file is shorter than 3 hours, no change is necessary. Your API requests with diarization will return results as expected. Users processing audio with diarization (diarize=true) and a duration of less than 3 hours. On-prem customers. Our customer\u00a0 \u00a0team is always available to work with you on any issues you may see with our latest version of the diarizer."
  },
  {
    "title": "New Method for Closing Streams",
    "description": "Deepgram\u2019s real-time API has been updated for enhanced usability. Streaming connections should now be closed by sending the JSON message\u00a0 { \"type\": \"CloseStream\" } \u00a0. Previously, streaming connections were closed by sending an empty byte. Here\u2019s an example of sending a CloseStream message in Javascript: And an example in Python: In the future, we will deprecate the ability to close the connection with an empty byte.\u00a0 We recommend customers using our API move to using the CloseStream method to avoid potential disruptions. Any customers using our SDK will not need to make changes."
  },
  {
    "title": "New Enhanced German Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include German to bring you the highest accuracy for German language support. For example, to call the Enhanced German Model, the URL query might look like https://api.deepgram.com/v1/listen?model=general&tier=enhanced&language=de&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new Model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs."
  },
  {
    "title": "New Enhanced Polish Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include Polish to bring you the highest accuracy for Polish language support. For example, to call the Enhanced Polish Model, the URL query might look like https://api.deepgram.com/v1/listen?model=general&tier=enhanced&language=pl&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new Model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs."
  },
  {
    "title": "New Enhanced Japanese Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include Japanese to bring you the highest accuracy for Japanese language support. For example, to call the Enhanced Japanese Model, the URL query might look like https://api.deepgram.com/v1/listen?model=general&tier=enhanced&language=ja&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new Model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs."
  },
  {
    "title": "New Enhanced Korean Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include Korean to bring you the highest accuracy for Korean language support. For example, to call the Enhanced Korean Model, the URL query might look like https://api.deepgram.com/v1/listen?model=general&tier=enhanced&language=ko&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new Model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs."
  },
  {
    "title": "New Enhanced Italian Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include Italian to bring you the highest accuracy for Italian language support. For example, to call the Enhanced Italian Model, the URL query might look like https://api.deepgram.com/v1/listen?model=general&tier=enhanced&language=it&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new Model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs."
  },
  {
    "title": "Deepgram Self-Hosted Release 221007",
    "description": "Deepgram released a new version of its on-premises solution. deepgram/onprem-api:1.70.0 deepgram/onprem-engine:3.37.2 deepgram/onprem-license-proxy:1.2.1 deepgram/onprem-billing:1.4.0 deepgram/onprem-metrics-server:2.0.0 Deepgram On-premises deployments now support the following Understanding features (with the accompanying Understanding model deployed on-prem and the requisite configuration changes): Deepgram On-premises deployments now support Deepgram Cloud\u2019s\u00a0/v1\u00a0endpoint schema. On startup, Engine will automatically enable\u00a0 \u00a0if it is supported by the NVIDIA GPU. Engine will now return an explicit error message indicating if the\u00a0model_manager\u00a0search path is misconfigured. Error: failure: Configuration contains inaccessible model search path(s) Time duration values can now be specified in configuration files using a human-readable format such as \u201c1h\u201d to represent 1 hour, \u201c2m\u201d to represent 2 minutes, \u201c60s\u201d to represent 60 seconds, etc. The streaming connection timeout between API and Engine is now configurable via the\u00a0streaming_timeout\u00a0parameter in the\u00a0 api.toml \u00a0file. [[driver_pool.standard]]\n  ...\n  streaming_conn_timeout = \"60s\" \u00a0 Resolves an issue where WebSocket callbacks were improperly shutdown, which prevented the WebSocket\u00a0 Close \u00a0frame from being issued in compliance with\u00a0 \u00a0and may have resulted in partial transcription data loss in the WebSocket callback. We welcome your feedback, please share it with us at\u00a0 ."
  },
  {
    "title": "New Enhanced Portuguese Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include Portuguese (Brazil and Portugal) to bring you the highest accuracy for Portuguese language support. For example, to call the Enhanced Portuguese Model, the URL query might look like https://api.deepgram.com/v1/listen?model=general&tier=enhanced&language=pt-BR&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new Model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs."
  },
  {
    "title": "New Base Polish Model",
    "description": "Deepgram is excited to announce our new Base Polish model. To call the Base Polish model, the URL query might look like: https://api.deepgram.com/v1/listen?model=general&tier=base&language=pl&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s . Before using the new Model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs."
  },
  {
    "title": "Introducing Language Detection",
    "description": "Today, we\u2019re very excited to announce the public release of our new Automatic Language Detection feature(detect_language=true),\u00a0which supports all of our generally available\u00a0 .\u00a0 Deepgram\u2019s speech recognition API, with Language Detection, can automatically detect the dominant language in an audio file and transcribe the output in the detected language. Language Detection API endpoint can be called using (detect_language=true) and will return\u00a0 detected_lanaguage \u00a0in the response body of the output. Examples of use cases for Language Detection include: Automatically generates the transcription in the detected dominant\u00a0language.\u00a0 Better organize and categorize a large amount of unstructured audio data based on the identified language. Customers with input audio files in different languages who need to automatically detect and transcribe the output in the detected language. \u00a0 The URL query might look like this to call the Language Detection API.\u00a0 Please see the features page in our documentation to learn more about\u00a0 . Please get in touch with us through your dedicated support channel. We\u2019d love to have your feedback, please share it with us at\u00a0"
  },
  {
    "title": "Introducing Topic Detection",
    "description": "We are very excited to announce our latest Speech Understanding feature \u2013 Topic Detection (detect_topics=true). Deepgram\u2019s Topic Detection API, in addition to our speech-to-text API, uses deep learning techniques to generate, identify and extract key topics from the audio data. Topic Detection API endpoint can be called using (detect_topics=true) and will return\u00a0 topics \u00a0block in the response body of the output. Each segment of the topics will have a section of the text, identified topics, confidence score, and word positions. Examples of use cases for Topic Detection include: Help the Quality Assurance team to analyze conversations based on discussed topics and identify trends and patterns. Extract meaningful and actionable insights from conversations and audio data based on discussed topics. Categorize and tag conversations based on identified topics to enhance search and recommendation capabilities. The URL query might look like this to call the Topic Detection API.\u00a0 . Please see the features page in our documentation to learn more about\u00a0 . We\u2019d love to have your feedback; please share it with us at\u00a0 , or you can also get in touch with us through your dedicated support channel."
  },
  {
    "title": "Introducing Summarization",
    "description": "We are excited to announce our latest Speech Understanding feature \u2013 Summarization ( summarize=true ). Deepgram\u2019s speech recognition API, with Summarization, can auto-generate meaningful summaries from the audio data. Summarization API endpoint can be called using ( summarize=true ) and will return\u00a0 summaries \u00a0block in the response body of the output. Each segment of the summary will have summarized text, start_word, and end_word. Examples of use cases for Summarization include: Automatically generate call notes and meeting summaries to reduce manual effort. Navigate through a large number of calls and analyze important conversations through generated summaries. Help listeners identify interesting conversations through auto-generated meaningful podcast previews. The URL query might look like this to call the Summarization API.\u00a0 . Please see the features page in our documentation to learn more about Summarization. Please get in touch with us through your dedicated support channel. We\u2019d love to have your feedback, please share it with us at\u00a0"
  },
  {
    "title": "New Enhanced Dutch Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include Dutch to bring you the highest accuracy for Dutch language support. For example, to call the General Enhanced Dutch Model, the URL query might look like https://api.deepgram.com/v1/listen?model=general&tier=enhanced&language=nl&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new Model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs."
  },
  {
    "title": "Deepgram Self-Hosted Release 220831",
    "description": "Deepgram released a new version of its on-premises solution. deepgram/onprem-api:1.64.0 deepgram/onprem-engine:3.33.0 deepgram/onprem-license-proxy:1.2.1 deepgram/onprem-billing:1.4.0 deepgram/onprem-metrics-server:2.0.0 Support for improved Diarization. The new Diarization model should be placed into the\u00a0 model_manager \u00a0search path and can be invoked by using the\u00a0 diarize=true \u00a0parameter in the ASR request. Please visit the\u00a0 \u00a0documentation page to learn more. ASR requests can invoke a specific model by passing the the model UUID instead of the model name for the\u00a0 model \u00a0URI parameter. Streaming\u00a0 \u00a0requests can now receive the transcript response in the requesting WebSocket (in addition to the callback) by including the\u00a0 inspect_response=true \u00a0parameter in the ASR request. Support for the deprecated\u00a0 weights \u00a0field in\u00a0 engine.toml \u00a0has been removed. Use the\u00a0 path \u00a0field moving forward. Streaming audio which is received >1.25x real-time speed is now throttled. Resolves a stability issue in the License Proxy Server."
  },
  {
    "title": "New Paragraph and Sentence Formatting",
    "description": "paragraphs=true&punctuate=true ( required \u2014 When \u00a0 paragraphs=true , punctuation, diarization, and/or multichannel must be enabled) Our new paragraphs feature breaks audio transcripts into nicely-formatted paragraphs and sentences for easier reading and parsing. The feature can be influenced by the addition of diarization or multichannel functionality to create breaks based on speaker or channel changes. The feature can be useful for performing analytics on finer segments of a conversation, say for sentiment analysis, or for presenting a transcript in a more readable format. To learn more about the feature, check out the feature guide in our\u00a0 . To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s ."
  },
  {
    "title": "New Enhanced Finance Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include Finance use-case model to bring you the highest accuracy. Finance model is optimized for multiple speakers with varying audio quality, such as might be found on a typical earnings call.\u00a0It is currently available for English. To call the Finance Enhanced English Model, the URL query might look like: https://api.deepgram.com/v1/listen?model=finance&tier=enhanced&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new Model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs. Deepgram support is always available to walk customers through updates, as well as resolve any issues that arise when upgrading."
  },
  {
    "title": "New Enhanced Meeting Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include Meeting use-case model to bring you the highest accuracy. Meeting model is optimized for conference room settings, which include multiple speakers with a single microphone. You can start using the Meeting Enhanced Model in Console now by specifying model as \u2018meeting\u2019 and tier as \u2018enhanced\u2019. It is currently available for English. For example, to call the Meeting English Enhanced Model, the URL query might look like https://api.deepgram.com/v1/listen?model=meeting&tier=enhanced&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new Model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs. Deepgram support is always available to walk customers through updates, as well as resolve any issues that arise when upgrading."
  },
  {
    "title": "Deepgram Self-Hosted Release 220708",
    "description": "Deepgram released a new version of its on-premises solution. deepgram/onprem-api:1.60.0 deepgram/onprem-engine:3.28.10 deepgram/onprem-license-proxy:1.1.0 deepgram/onprem-billing:1.4.0 deepgram/onprem-metrics-server:2.0.0 \u00a0 Deepgram On-premises now supports Enhanced models for ASR requests. Transcription Find and Replace is now supported via the\u00a0 replace \u00a0URI parameter. To learn more, please visit the feature page for\u00a0 . The\u00a0 /v2/models \u00a0endpoint response now includes the model UUID for cross-referencing against the model UUID listed in the\u00a0 /v2/listen \u00a0response. Any\u00a0 [[post_processing_info.plugins]] \u00a0sections defined in the\u00a0 api.toml \u00a0file will need to be deleted to get properly formatted responses with this release."
  },
  {
    "title": "Introducing Enhanced Phonecall Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include Phonecall use-case model to bring you the highest accuracy. Phonecall model is optimized for low-bandwidth audio phone calls. You can start using the Phonecall Enhanced Model in Console now by specifying model as \u2018phonecall\u2019 and tier as \u2018enhanced\u2019. It is currently available for English. For example, to call the Phonecall English Enhanced Model, the URL query might look like https://api.deepgram.com/v1/listen?model=phonecall&tier=enhanced&punctuate=true To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new Model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs. Deepgram support is always available to walk customers through updates, as well as resolve any issues that arise when upgrading."
  },
  {
    "title": "New from Deepgram: Enhanced Spanish Model",
    "description": "Deepgram is excited to announce expanding our newest, most powerful ASR model tier, Enhanced, to include Spanish to bring you the highest accuracy for Spanish language support. You can start using the General Enhanced Spanish Model in Console now by specifying model as \u2018general\u2019, tier as \u2018enhanced\u2019 and language as \u2018es\u2019. For example, to call the General Enhanced Spanish Model, the URL query might look like To learn more about the various parameters you can use to customize your transcriptions with Deepgram, check out the list of Deepgram\u2019s .\u00a0 Before using the new Model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs. Deepgram support is always available to walk customers through updates, as well as resolve any issues that arise when upgrading."
  },
  {
    "title": "Introducing New Enhanced Model",
    "description": "Deepgram is excited to announce our newest, most powerful ASR model, Enhanced model. The new Enhanced model is based on our next generation End-to-End Deep Learning speech model architecture.\u00a0Key features and benefits include: The new model has significantly higher accuracy and better word recognition. It has 19% higher accuracy relative compared to our previous model. It has increased effective vocabulary. It handles the long tail vocabulary significantly better. Many of our customers have confirmed that it provides best in the industry accuracy with the highest speed right out of the box! With the introduction of the new model, our customers can now select from three powerful solution tiers: our Base model, Enhanced model and our trained models. You can start using the Enhanced Model in Console now by specifying model as \u2018general-enhanced\u2019. It is currently available for English. Sample Curl code: curl \\ -X POST \\ \"https://api.deepgram.com/v1/listen?model=general-enhanced&punctuate=true\" \\ -H \"Authorization:Token YOUR_SECRET\" \\ -H 'content-type: application/json' \\ -d '{\"url\":\"https://static.deepgram.com/examples/Bueller-Life-moves-pretty-fast.wav\"}' Read more about Deepgram Enhanced Model in the\u00a0 . Before using the new Model in production, we recommend testing it alongside your typical feature adds, like keywords. Model updates may change transcription outputs. \u00a0is always available to walk customers through updates, as well as resolve any issues that arise when upgrading."
  },
  {
    "title": "Deepgram Self-Hosted Release 220428",
    "description": "Deepgram released a new version of its on-premises solution. deepgram/onprem-api:1.58.0 deepgram/onprem-engine:3.26.7 deepgram/onprem-license-proxy:1.0.0-1 deepgram/onprem-metrics-server:2.0.0 Failover Drivers \u00a0are now deprecated. Customers with Deepgram Engine instances configured as failover drivers in their\u00a0 api.toml \u00a0file must change their configuration to list all Deepgram Engine instances as standard drivers. Resolves the following CVEs in supporting libraries. Deprecates\u00a0 GPU Utilization \u00a0in\u00a0 onprem-metrics-server . GA release of\u00a0\u00a0 onprem-license-proxy . Please refer to the\u00a0 \u00a0documentation for more information."
  },
  {
    "title": "More Language Models, Better Accuracy",
    "description": "Following our mission to make every voice be heard and understood, Deepgram has been working hard to release language models to support many more global languages, and we\u2019re continually working to improve accuracy across all of our existing language models. For a limited time, many of our language models are free to use! See our\u00a0 \u00a0for the full list of supported languages and current information on which language models are free to use, or explore our\u00a0 \u00a0for information on how to call each available language model. Newly-Released Language Models Chinese (Mandarin, Simplified) Chinese (Mandarin, Traditional) Dutch French Canadian Indonesian Italian Japanese Latin American Spanish Russian Swedish Ukrainian Improved Production Language Models Korean Spanish\u00a0 To easily test these languages, and many more, sign up for a\u00a0 ! New accounts get $150 in free credits. All API calls to a language model default to the most recent version. To call a previous version of our models,\u00a0 \u00a0and use version={desired_version}.\u00a0"
  },
  {
    "title": "Deepgram Self-Hosted Release 220323",
    "description": "Deepgram released a new version of on-premises Deepgram Engine and Deepgram API. Current customers may pull these version from Docker Hub as\u00a0 deepgram/onprem-engine:3.22.13 \u00a0and\u00a0 deepgram/onprem-api:1.49.11 . deepgram/onprem-engine:3.22.13 deepgram/onprem-api:1.49.11 deepgram/metrics-server:1.02 Resolves the following CVEs in supporting libraries. Deepgram support,\u00a0 , is always available to help walk customers through new feature purpose and configuration, as well as resolve any issues that arise when upgrading.\nRead more about Deepgram\u2019s On-Prem Support in the\u00a0 ."
  },
  {
    "title": "Update to Streaming Interim Results Default Behavior",
    "description": "Default behavior for Interim Results has changed for Streaming Transcription on\u00a0 . Currently, Interim Results default to\u00a0 . From March 14, 2022, Interim Results defaults to\u00a0 . To prevent any interruption in services, please update your transcription request to include\u00a0 . Learn more about Interim Results in our documentation:\u00a0"
  },
  {
    "title": "Deepgram Self-Hosted Release 220307",
    "description": "Deepgram released a new version of the on-premises Speech Engine and Metrics Server. Current customers may pull these version from Docker Hub as\u00a0 \u00a0and\u00a0 . This release: Resolves the following CVEs in supporting libraries. Resolves an issue which prevented\u00a0 deepgram/metrics-server \u00a0from reporting valid system KPIs. Please note that the\u00a0 GPU Utilization \u00a0metric is deprecated in this release and will be removed from future releases of Metrics Server. On-Premises Release 220307: deepgram/onprem-engine:3.22.12 deepgram/onprem-api:1.49.1 deepgram/metrics-server:1.02 Deepgram support,\u00a0 , is always available to help walk customers through new feature purpose and configuration, as well as resolve any issues that arise when upgrading.\nRead more about Deepgram\u2019s On-Prem Support in the\u00a0 ."
  },
  {
    "title": "Updates to Base Models: General (en-US), Phonecall (en-US), and Meeting (en-US)",
    "description": "Deepgram is proud to announce significant updates to three of our base models \u2014 General (en-US), Phonecall (en-US), and Meeting (en-US). These improvements greatly improve accuracy and expand model vocabulary. If you do not wish to use \u00a0the latest version that was deployed as the default on January 18, 2022, \u00a0you may pin to a previous version by specifying the desired version as\u00a0 version={desired_version} . If no\u00a0 version \u00a0is specified, we will use our latest model by default.\u00a0See below for previous versions. General ( model=general ) 2021-05-19.0 2021-03-17.0 2021-02-10.0 Phonecall ( model=phonecall ) 2021-05-19.0 2021-03-17.0 2021-02-10.0 Meeting ( model=meeting ) 2021-05-19.0 2021-03-17.0 2021-02-10.0 Before using these updated models in production, we recommend testing them alongside your typical feature adds, like keywords. Model updates may change transcription outputs. \u00a0is always available to walk customers through updates, as well as resolve any issues that arise when upgrading."
  },
  {
    "title": "Five new languages and three new use case speech models",
    "description": "We are announcing five new languages and three new use case speech models.\u00a0 In addition, we have improved our Hindi and Spanish language models and our Conversational AI and Meetings models.\u00a0 These improvements mean better accuracy for your transcription applications. Improved Production Language Models Hindi (improved) Spanish (improved) New Language Models French French Canadian German Our French and German language models are FREE for the next 30 days of use to collect more audio for training and improvement.\u00a0\u00a0 \u00a0to get early access.\u00a0 New and Improved Use Case Models Conversational AI (improved) Earnings Calls Meetings (improved) Voicemail Video"
  },
  {
    "title": "Updates to our Speech Recognition API",
    "description": "Deepgram has released an update to our Speech Recognition API. Improvements affect the following areas: We have increased the accuracy of out-of-vocabulary (OOV)\u00a0 \u00a0by reducing false positives when processing pre-recorded audio. Response objects sent from transcription endpoints (/listen) will now include unique identifiers for models: Batch : The\u00a0metadata\u00a0object will now include a\u00a0models\u00a0field (array of strings), which lists the unique identifiers of all models used during transcription.\u00a0 . Streaming : For each interim transcript, the\u00a0metadata\u00a0object will now include a\u00a0model_uuid\u00a0field (string), which lists the unique identifier for the model used to transcribe the particular channel and chunk of data. The last response returned during streaming will not include this field.\u00a0 , or to learn more about interim transcripts, see\u00a0 \u00a0in Deepgram\u2019s Developer Documentation. Transcript : The\u00a0metadata\u00a0object will now include a\u00a0models\u00a0field (array of strings), which includes the unique identifiers of all models used during transcription.\u00a0 . \u00a0is always available to walk customers through updates, as well as resolve any issues that arise when upgrading."
  },
  {
    "title": "Now in General Availability: Utterance Formatting",
    "description": "=true (optional parameter\u00a0 utt_split =number) Our new utterances feature segments speech into meaningful semantic units, which allows the chosen model to interact more naturally and effectively with speakers\u2019 spontaneous speech patterns. For example, when humans speak to each other conversationally, they often pause mid-sentence to reformulate their thoughts, or stop and restart a badly-worded sentence. When\u00a0 utterances \u00a0is set to\u00a0 true , these utterances are identified, so you can present a transcript with a more natural speaking pattern. The feature can be useful for performing analytics on finer segments of a conversation, say for sentiment analysis, or for presenting a transcript in a more readable format. To learn more about the feature, check out the feature guide in our\u00a0 ."
  },
  {
    "title": "New from Deepgram Labs: Hindi Support",
    "description": "language =hi Deepgram now supports automatic transcription for Hindi with the general model (model=general). The new language has been trained on a variety of data ranging from basic conversations to domain-specific call center audio. To learn more about the newly supported language and participate in the open beta, refer to the\u00a0 . If you opt in to testing the feature, Deepgram\u2019s Product team may contact you for a 15 minute feedback session to learn about your experience and use case."
  },
  {
    "title": "Improved Spanish Support",
    "description": "language=es new \u00a0version =\u00a0 2021-05-19.0 previous \u00a0version =\u00a0 2021-02-10.0 We have done additional training to improve the accuracy and expand the vocabulary of our Spanish language support. To use the latest Spanish support, pass the\u00a0 language=es \u00a0as an API parameter in your request. If you do not wish to use the latest version, be sure to specify the desired version as\u00a0 version={desired_version} . Previous versions include: 2021-02-10.0 2020-11-24.0 Note that Spanish support is only available with Deepgram\u2019s General Model ( model=general ). Read more about specifying\u00a0languages\u00a0in the\u00a0 ."
  },
  {
    "title": "Updated Phonecall Model (English US)",
    "description": "model=phonecall version=2021-05-19.0 We have done additional training to our base Phonecall Model for US English to improve accuracy and expand the model vocabulary.\u00a0 We\u2019ve also incorporated our latest improvements to punctuation ( punctuate=true ). To use the latest meeting model, pass the\u00a0 model=phonecall \u00a0as an API parameter in your request. If you do not wish to use the latest version, be sure to specify the desired version as\u00a0 version={desired_version} . Previous versions include: 2021-03-17.0 2021-02-10.0 2020-12-07.0 \u00a0 \u00a0To get early access to updated base models, use\u00a0 model={desired_model}&version=beta . Read more about selecting\u00a0models\u00a0and versions in the\u00a0 ."
  }
]